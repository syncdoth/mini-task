{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "similarity approach.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBWJRscyoAL0",
        "outputId": "98c7ca93-87c5-405e-96b9-6a085542a218"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DqTBZrQxL8M",
        "outputId": "0edd15df-bcc4-44ad-8309-fbdb6db7929b"
      },
      "source": [
        "!pip install pywsd\n",
        "!pip install -U wn==0.0.23"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pywsd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/bb/427a49c461b0970c124509f77d2cd75bdca0daa746155c45d065f0af93e3/pywsd-1.2.4.tar.gz (26.8MB)\n",
            "\u001b[K     |████████████████████████████████| 26.8MB 115kB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pywsd) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.1.5)\n",
            "Collecting wn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/56/94eb20054409cdfe6dbf95f8f7253ab0aa36d8fc517ac42ccb0575a3a502/wn-0.4.0-py3-none-any.whl (44kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pywsd) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pywsd) (2018.9)\n",
            "Collecting requests~=2.25\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml~=0.10 in /usr/local/lib/python3.6/dist-packages (from wn->pywsd) (0.10.2)\n",
            "Requirement already satisfied: importlib_resources; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from wn->pywsd) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests~=2.25->wn->pywsd) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests~=2.25->wn->pywsd) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests~=2.25->wn->pywsd) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests~=2.25->wn->pywsd) (2.10)\n",
            "Requirement already satisfied: zipp>=0.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib_resources; python_version < \"3.7\"->wn->pywsd) (3.4.0)\n",
            "Building wheels for collected packages: pywsd\n",
            "  Building wheel for pywsd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pywsd: filename=pywsd-1.2.4-cp36-none-any.whl size=26940454 sha256=25a5540a13d950d6d0f7d1c2036f73c5913874b09c3f8f88c872a89581c0de8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/4d/d2/405b948047f7f3851f16ab9d893ce7c1a3010182900884536b\n",
            "Successfully built pywsd\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: requests, wn, pywsd\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed pywsd-1.2.4 requests-2.25.1 wn-0.4.0\n",
            "Collecting wn==0.0.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/f6/72db36e8afc977ae1a1cbb22afc77fd9b514e9bc6927ae8f4aae36665961/wn-0.0.23.tar.gz (31.6MB)\n",
            "\u001b[K     |████████████████████████████████| 31.6MB 109kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wn\n",
            "  Building wheel for wn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wn: filename=wn-0.0.23-cp36-none-any.whl size=31792944 sha256=eb79206d9719b93a28cd1c6fd5a993477f8da2a16a87f908102fb5c1fcea1f08\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/e3/c4/886021dbf4d758dc3cb9ddaa47d7d6fc895240d83f010e6305\n",
            "Successfully built wn\n",
            "Installing collected packages: wn\n",
            "  Found existing installation: wn 0.4.0\n",
            "    Uninstalling wn-0.4.0:\n",
            "      Successfully uninstalled wn-0.4.0\n",
            "Successfully installed wn-0.0.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHOMXhjfxm9Q",
        "outputId": "7e98761d-3772-41d6-d7d8-7c1ab9b8ed2b"
      },
      "source": [
        "%cd /content/drive/MyDrive/task"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/task\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKk4AtCrn2Qb",
        "outputId": "55f21f4f-b630-4be7-a4b7-21e9f4c0a781"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "from scipy import sparse\n",
        "from tensorflow import keras\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from Datasets import SimilarityDataset\n",
        "from models import SimilarityModel\n",
        "from utility import top_k_metric, calculating_class_weights, get_weighted_loss"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTb3vO9Ln1Da"
      },
      "source": [
        "import json\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "\n",
        "if os.path.exists(\"/content/drive/MyDrive/input_tokenizer.json\"):\n",
        "    with open(\"/content/drive/MyDrive/input_tokenizer.json\") as f:\n",
        "        data = json.load(f)\n",
        "        input_tokenizer = tokenizer_from_json(data)\n",
        "else:\n",
        "    input_tokenizer = None\n",
        "\n",
        "if os.path.exists(\"/content/drive/MyDrive/target_tokenizer.json\"):\n",
        "    with open(\"/content/drive/MyDrive/target_tokenizer.json\") as f:\n",
        "        data = json.load(f)\n",
        "        target_tokenizer = tokenizer_from_json(data)\n",
        "else:\n",
        "    target_tokenizer = None\n",
        "\n",
        "if os.path.exists(\"/content/drive/MyDrive/new_vocab_sim_mat.npz\"):\n",
        "    sim_mat = sparse.load_npz(\"/content/drive/MyDrive/new_vocab_sim_mat.npz\")\n",
        "else:\n",
        "    sim_mat = None"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FOHzZ-Gn2Qk"
      },
      "source": [
        "train_ds = SimilarityDataset(mode=\"train\", \n",
        "                             tag_func=nltk.pos_tag_sents, \n",
        "                             input_tokenizer=input_tokenizer, \n",
        "                             target_tokenizer=target_tokenizer, \n",
        "                             sim_mat=sim_mat)\n",
        "val_ds = SimilarityDataset(mode=\"valid\", \n",
        "                           tag_func=nltk.pos_tag_sents, \n",
        "                           input_tokenizer=train_ds.input_tokenizer, \n",
        "                           target_tokenizer=train_ds.target_tokenizer)\n",
        "test_ds = SimilarityDataset(mode=\"test\", \n",
        "                            tag_func=nltk.pos_tag_sents, \n",
        "                            input_tokenizer=train_ds.input_tokenizer, \n",
        "                            target_tokenizer=train_ds.target_tokenizer)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwHUVMqbxL8N",
        "outputId": "758d2d4b-e640-4872-c4e9-8157bb0d1662"
      },
      "source": [
        "train_data, train_labels = train_ds.get_data_target()\n",
        "val_data, val_labels = val_ds.get_data_target()\n",
        "test_data, test_labels = test_ds.get_data_target()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finished loading corpus\n",
            "finished loading descriptions\n",
            "finished extracting contexts\n",
            "finished extracting targets (OOCs)\n",
            "finished loading corpus\n",
            "finished loading descriptions\n",
            "finished extracting contexts\n",
            "finished extracting targets (OOCs)\n",
            "finished loading corpus\n",
            "finished loading descriptions\n",
            "finished extracting contexts\n",
            "finished extracting targets (OOCs)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWUKN1YWcOST"
      },
      "source": [
        "## Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InxmlMtHJVMq"
      },
      "source": [
        "import json\n",
        "\n",
        "input_tokenizer_json = train_ds.input_tokenizer.to_json()\n",
        "with open(\"/content/drive/MyDrive/input_tokenizer.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(json.dumps(input_tokenizer_json, ensure_ascii=False))\n",
        "\n",
        "target_tokenizer_json = train_ds.target_tokenizer.to_json()\n",
        "with open(\"/content/drive/MyDrive/target_tokenizer.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(json.dumps(target_tokenizer_json, ensure_ascii=False))\n",
        "\n",
        "# Load as:\n",
        "# with open('tokenizer.json') as f:\n",
        "#     data = json.load(f)\n",
        "#     tokenizer = tokenizer_from_json(data)\n",
        "\n",
        "sparse.save_npz(\"/content/drive/MyDrive/new_vocab_sim_mat\", train_ds.sim_mat)\n",
        "\n",
        "# Load as:\n",
        "# sim_mat = sparse.load_npz(\"/content/drive/MyDrive/sim_mat\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRjwKrVsgxJC"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9u1MpMGpyWQ"
      },
      "source": [
        "class_weights = calculating_class_weights(train_labels)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MZHYa-9n2Ql"
      },
      "source": [
        "model = SimilarityModel()\n",
        "model.build_model(\n",
        "        len(train_ds.input_tokenizer.word_index) + 1,\n",
        "        train_labels.shape[-1],\n",
        "        (train_data.shape[1],),\n",
        "        train_ds.sim_mat.toarray(),\n",
        "        loss=get_weighted_loss(class_weights),\n",
        "        metrics=[\n",
        "            keras.metrics.Precision(name='precision', top_k=5),\n",
        "            keras.metrics.Recall(name='recall', top_k=5),\n",
        "        ],\n",
        "        hidden_sizes=[1024, 1024])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klzClaUkn2Ql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c197f9-5b12-422b-f347-014d241ce10b"
      },
      "source": [
        "model.train(train_data, train_labels, val_data, val_labels, batch_size=32, epochs=50)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "270/270 [==============================] - 13s 45ms/step - loss: 0.8895 - precision: 2.8692e-04 - recall: 6.5784e-04 - val_loss: 0.6283 - val_precision: 0.0011 - val_recall: 0.0027\n",
            "Epoch 2/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.7246 - precision: 0.0010 - recall: 0.0024 - val_loss: 0.6205 - val_precision: 0.0017 - val_recall: 0.0041\n",
            "Epoch 3/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.7015 - precision: 0.0017 - recall: 0.0040 - val_loss: 0.6153 - val_precision: 0.0013 - val_recall: 0.0032\n",
            "Epoch 4/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6879 - precision: 0.0026 - recall: 0.0059 - val_loss: 0.6147 - val_precision: 0.0026 - val_recall: 0.0064\n",
            "Epoch 5/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6859 - precision: 0.0029 - recall: 0.0066 - val_loss: 0.6136 - val_precision: 0.0024 - val_recall: 0.0059\n",
            "Epoch 6/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6788 - precision: 0.0021 - recall: 0.0048 - val_loss: 0.6141 - val_precision: 0.0021 - val_recall: 0.0050\n",
            "Epoch 7/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6682 - precision: 0.0028 - recall: 0.0064 - val_loss: 0.6149 - val_precision: 0.0013 - val_recall: 0.0032\n",
            "Epoch 8/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6805 - precision: 0.0034 - recall: 0.0077 - val_loss: 0.6155 - val_precision: 0.0055 - val_recall: 0.0132\n",
            "Epoch 9/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.6589 - precision: 0.0034 - recall: 0.0078 - val_loss: 0.6189 - val_precision: 0.0056 - val_recall: 0.0136\n",
            "Epoch 10/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6654 - precision: 0.0050 - recall: 0.0114 - val_loss: 0.6217 - val_precision: 0.0053 - val_recall: 0.0127\n",
            "Epoch 11/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6560 - precision: 0.0046 - recall: 0.0107 - val_loss: 0.6224 - val_precision: 0.0038 - val_recall: 0.0091\n",
            "Epoch 12/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6563 - precision: 0.0048 - recall: 0.0111 - val_loss: 0.6300 - val_precision: 0.0030 - val_recall: 0.0073\n",
            "Epoch 13/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6376 - precision: 0.0045 - recall: 0.0105 - val_loss: 0.6334 - val_precision: 0.0040 - val_recall: 0.0096\n",
            "Epoch 14/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6341 - precision: 0.0058 - recall: 0.0133 - val_loss: 0.6357 - val_precision: 0.0064 - val_recall: 0.0155\n",
            "Epoch 15/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6376 - precision: 0.0059 - recall: 0.0135 - val_loss: 0.6410 - val_precision: 0.0053 - val_recall: 0.0127\n",
            "Epoch 16/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6225 - precision: 0.0069 - recall: 0.0159 - val_loss: 0.6476 - val_precision: 0.0060 - val_recall: 0.0146\n",
            "Epoch 17/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6155 - precision: 0.0067 - recall: 0.0155 - val_loss: 0.6542 - val_precision: 0.0053 - val_recall: 0.0127\n",
            "Epoch 18/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6115 - precision: 0.0070 - recall: 0.0160 - val_loss: 0.6593 - val_precision: 0.0062 - val_recall: 0.0150\n",
            "Epoch 19/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6107 - precision: 0.0089 - recall: 0.0205 - val_loss: 0.6677 - val_precision: 0.0072 - val_recall: 0.0173\n",
            "Epoch 20/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6105 - precision: 0.0092 - recall: 0.0211 - val_loss: 0.6828 - val_precision: 0.0098 - val_recall: 0.0237\n",
            "Epoch 21/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6002 - precision: 0.0101 - recall: 0.0232 - val_loss: 0.6883 - val_precision: 0.0079 - val_recall: 0.0191\n",
            "Epoch 22/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.6033 - precision: 0.0103 - recall: 0.0234 - val_loss: 0.6952 - val_precision: 0.0070 - val_recall: 0.0168\n",
            "Epoch 23/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.5939 - precision: 0.0107 - recall: 0.0244 - val_loss: 0.7084 - val_precision: 0.0092 - val_recall: 0.0223\n",
            "Epoch 24/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.5855 - precision: 0.0120 - recall: 0.0276 - val_loss: 0.7147 - val_precision: 0.0090 - val_recall: 0.0218\n",
            "Epoch 25/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.5817 - precision: 0.0120 - recall: 0.0273 - val_loss: 0.7293 - val_precision: 0.0113 - val_recall: 0.0273\n",
            "Epoch 26/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.5810 - precision: 0.0135 - recall: 0.0307 - val_loss: 0.7443 - val_precision: 0.0124 - val_recall: 0.0300\n",
            "Epoch 27/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.5577 - precision: 0.0138 - recall: 0.0315 - val_loss: 0.7401 - val_precision: 0.0094 - val_recall: 0.0227\n",
            "Epoch 28/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.5572 - precision: 0.0134 - recall: 0.0310 - val_loss: 0.7507 - val_precision: 0.0105 - val_recall: 0.0255\n",
            "Epoch 29/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.5617 - precision: 0.0127 - recall: 0.0291 - val_loss: 0.7798 - val_precision: 0.0121 - val_recall: 0.0291\n",
            "Epoch 30/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.5462 - precision: 0.0145 - recall: 0.0333 - val_loss: 0.7995 - val_precision: 0.0094 - val_recall: 0.0227\n",
            "Epoch 31/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.5423 - precision: 0.0135 - recall: 0.0311 - val_loss: 0.8094 - val_precision: 0.0109 - val_recall: 0.0264\n",
            "Epoch 32/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.5295 - precision: 0.0132 - recall: 0.0305 - val_loss: 0.8282 - val_precision: 0.0109 - val_recall: 0.0264\n",
            "Epoch 33/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.5230 - precision: 0.0140 - recall: 0.0324 - val_loss: 0.8301 - val_precision: 0.0107 - val_recall: 0.0259\n",
            "Epoch 34/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.5206 - precision: 0.0130 - recall: 0.0299 - val_loss: 0.8531 - val_precision: 0.0104 - val_recall: 0.0250\n",
            "Epoch 35/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.5098 - precision: 0.0141 - recall: 0.0327 - val_loss: 0.8675 - val_precision: 0.0105 - val_recall: 0.0255\n",
            "Epoch 36/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.5055 - precision: 0.0151 - recall: 0.0345 - val_loss: 0.8945 - val_precision: 0.0107 - val_recall: 0.0259\n",
            "Epoch 37/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.5004 - precision: 0.0143 - recall: 0.0330 - val_loss: 0.9191 - val_precision: 0.0128 - val_recall: 0.0309\n",
            "Epoch 38/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.4906 - precision: 0.0149 - recall: 0.0339 - val_loss: 0.9432 - val_precision: 0.0104 - val_recall: 0.0250\n",
            "Epoch 39/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4857 - precision: 0.0135 - recall: 0.0312 - val_loss: 0.9615 - val_precision: 0.0105 - val_recall: 0.0255\n",
            "Epoch 40/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4741 - precision: 0.0145 - recall: 0.0332 - val_loss: 1.0008 - val_precision: 0.0109 - val_recall: 0.0264\n",
            "Epoch 41/50\n",
            "270/270 [==============================] - 12s 44ms/step - loss: 0.4731 - precision: 0.0131 - recall: 0.0301 - val_loss: 1.0088 - val_precision: 0.0087 - val_recall: 0.0209\n",
            "Epoch 42/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4634 - precision: 0.0125 - recall: 0.0287 - val_loss: 1.0548 - val_precision: 0.0113 - val_recall: 0.0273\n",
            "Epoch 43/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4597 - precision: 0.0147 - recall: 0.0336 - val_loss: 1.0941 - val_precision: 0.0115 - val_recall: 0.0278\n",
            "Epoch 44/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4451 - precision: 0.0151 - recall: 0.0347 - val_loss: 1.1029 - val_precision: 0.0105 - val_recall: 0.0255\n",
            "Epoch 45/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4417 - precision: 0.0144 - recall: 0.0329 - val_loss: 1.1497 - val_precision: 0.0105 - val_recall: 0.0255\n",
            "Epoch 46/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4312 - precision: 0.0158 - recall: 0.0361 - val_loss: 1.1702 - val_precision: 0.0094 - val_recall: 0.0227\n",
            "Epoch 47/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4363 - precision: 0.0136 - recall: 0.0310 - val_loss: 1.2201 - val_precision: 0.0137 - val_recall: 0.0332\n",
            "Epoch 48/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4261 - precision: 0.0154 - recall: 0.0353 - val_loss: 1.2641 - val_precision: 0.0096 - val_recall: 0.0232\n",
            "Epoch 49/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4126 - precision: 0.0123 - recall: 0.0282 - val_loss: 1.2932 - val_precision: 0.0096 - val_recall: 0.0232\n",
            "Epoch 50/50\n",
            "270/270 [==============================] - 12s 45ms/step - loss: 0.4107 - precision: 0.0157 - recall: 0.0362 - val_loss: 1.3476 - val_precision: 0.0115 - val_recall: 0.0278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6234402630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAnTW2lWqpHP"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpIoGYnBgAD-"
      },
      "source": [
        "train_pred = model.infer(train_data)\n",
        "val_pred = model.infer(val_data)\n",
        "test_pred = model.infer(test_data)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wkkfAaEo1Ac",
        "outputId": "a67e7bde-8b6e-4404-936e-0c60dc89aa23"
      },
      "source": [
        "for i in range(1, 11):\n",
        "    metric = top_k_metric(train_pred, train_labels, i)\n",
        "    print(f\"top {i}: \\nprecision: {metric[0]}\\nrecall: {metric[1]}\\nf1: {metric[2]}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top 1: \n",
            "precision: 0.021946121690664188\n",
            "recall: 0.010412934333045805\n",
            "f1: 0.014124239215289568\n",
            "top 2: \n",
            "precision: 0.021191360891778914\n",
            "recall: 0.020380753323159268\n",
            "f1: 0.020778154158067646\n",
            "top 3: \n",
            "precision: 0.01931413531506425\n",
            "recall: 0.02731888505518324\n",
            "f1: 0.022629486077600822\n",
            "top 4: \n",
            "precision: 0.017620761727821645\n",
            "recall: 0.032897756176320965\n",
            "f1: 0.02294934796237914\n",
            "top 5: \n",
            "precision: 0.016720854621458434\n",
            "recall: 0.03926014088868246\n",
            "f1: 0.023453070179815495\n",
            "top 6: \n",
            "precision: 0.015811271094596686\n",
            "recall: 0.0446800422444872\n",
            "f1: 0.02335701512994521\n",
            "top 7: \n",
            "precision: 0.015028863380001325\n",
            "recall: 0.049570643399022396\n",
            "f1: 0.023064895212004312\n",
            "top 8: \n",
            "precision: 0.014282396655829076\n",
            "recall: 0.053354123813947316\n",
            "f1: 0.022532937952523\n",
            "top 9: \n",
            "precision: 0.013830830365897714\n",
            "recall: 0.0579233295733528\n",
            "f1: 0.022329792341943402\n",
            "top 10: \n",
            "precision: 0.013446353924756153\n",
            "recall: 0.06236508305133479\n",
            "f1: 0.022122862003513467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1DKoBEcfAkJ",
        "outputId": "2e7e6fd2-11be-401b-ad80-c93ef102d42e"
      },
      "source": [
        "for i in range(1, 11):\n",
        "    metric = top_k_metric(val_pred, val_labels, i)\n",
        "    print(f\"top {i}: \\nprecision: {metric[0]}\\nrecall: {metric[1]}\\nf1: {metric[2]}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top 1: \n",
            "precision: 0.015065913370998116\n",
            "recall: 0.008866917765222849\n",
            "f1: 0.011163594825723194\n",
            "top 2: \n",
            "precision: 0.01224105461393597\n",
            "recall: 0.013135593220338982\n",
            "f1: 0.01267255746674633\n",
            "top 3: \n",
            "precision: 0.011299435028248588\n",
            "recall: 0.016650973006905212\n",
            "f1: 0.013462886653533691\n",
            "top 4: \n",
            "precision: 0.011064030131826741\n",
            "recall: 0.02170433145009416\n",
            "f1: 0.014656660605667032\n",
            "top 5: \n",
            "precision: 0.011487758945386064\n",
            "recall: 0.02715003138731952\n",
            "f1: 0.016144454082467823\n",
            "top 6: \n",
            "precision: 0.010514752040175768\n",
            "recall: 0.029613935969868173\n",
            "f1: 0.015519231208300096\n",
            "top 7: \n",
            "precision: 0.01022329835889158\n",
            "recall: 0.03427495291902071\n",
            "f1: 0.015749071474277957\n",
            "top 8: \n",
            "precision: 0.009887005649717515\n",
            "recall: 0.0374450721908349\n",
            "f1: 0.015643498329062328\n",
            "top 9: \n",
            "precision: 0.009102322661644695\n",
            "recall: 0.03833961079723791\n",
            "f1: 0.014711858592390336\n",
            "top 10: \n",
            "precision: 0.008662900188323918\n",
            "recall: 0.040725047080979286\n",
            "f1: 0.014286765801525622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6TJTh1tILDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e10ce2b-88ce-4c56-b0df-1cc8d991097b"
      },
      "source": [
        "for i in range(1, 11):\n",
        "    metric = top_k_metric(test_pred, test_labels, i)\n",
        "    print(f\"top {i}: \\nprecision: {metric[0]}\\nrecall: {metric[1]}\\nf1: {metric[2]}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top 1: \n",
            "precision: 0.015065913370998116\n",
            "recall: 0.008866917765222849\n",
            "f1: 0.011163594825723194\n",
            "top 2: \n",
            "precision: 0.01224105461393597\n",
            "recall: 0.014908976773383553\n",
            "f1: 0.013443932812993262\n",
            "top 3: \n",
            "precision: 0.011299435028248588\n",
            "recall: 0.019617074701820465\n",
            "f1: 0.014339384553614958\n",
            "top 4: \n",
            "precision: 0.01012241054613936\n",
            "recall: 0.02299121155053358\n",
            "f1: 0.014056238341321478\n",
            "top 5: \n",
            "precision: 0.009792843691148776\n",
            "recall: 0.026632140615191462\n",
            "f1: 0.01432008250226581\n",
            "top 6: \n",
            "precision: 0.008631512868801004\n",
            "recall: 0.027369742623979912\n",
            "f1: 0.013124113725535267\n",
            "top 7: \n",
            "precision: 0.008205542103847187\n",
            "recall: 0.030194601381042057\n",
            "f1: 0.01290427849773633\n",
            "top 8: \n",
            "precision: 0.007650659133709981\n",
            "recall: 0.03145009416195856\n",
            "f1: 0.012307381821356453\n",
            "top 9: \n",
            "precision: 0.007428332287089349\n",
            "recall: 0.03325486503452605\n",
            "f1: 0.01214399083169011\n",
            "top 10: \n",
            "precision: 0.007062146892655367\n",
            "recall: 0.035451977401129944\n",
            "f1: 0.011778065581770747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-pz9hCIbjAK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}